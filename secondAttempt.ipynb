{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706825a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from preprocessing import ReviewPreprocessor\n",
    "from embeddings import EmbeddingsManager\n",
    "from sentiments import Sentiments\n",
    "\n",
    "# Create an instance of classes used in the script\n",
    "sentimentsManager: Sentiments = None\n",
    "embeddingManager: EmbeddingsManager = None\n",
    "preprocessor: ReviewPreprocessor = None\n",
    "\n",
    "seed = 1967\n",
    "file_path = \"digital_music.jsonl\"\n",
    "topicGeneral = os.path.splitext(os.path.basename(file_path))[0]\n",
    "topicPath = os.path.join(\"data\", topicGeneral)\n",
    "if not os.path.exists(topicPath):\n",
    "    os.makedirs(topicPath)\n",
    "# Create a directory for the topic and seed\n",
    "topicSeedPath = os.path.join(topicPath, str(seed))\n",
    "if not os.path.exists(topicSeedPath):\n",
    "    os.makedirs(topicSeedPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d322c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set result file (CSV format, containing original and adjusted ratings)\n",
    "result_file = os.path.join(topicGeneral, f\"{topicGeneral}_results.csv\")\n",
    "\n",
    "# Instantiate the embeddings manager\n",
    "#embeddingManager = EmbeddingsManager(cachePath = topicPath)\n",
    "# Initialize sentiment cache using the instance method\n",
    "sentimentsManager = Sentiments(cachePath=topicPath)\n",
    "# Instantiate the ReviewPreprocessor class (which now handles cache initialization)\n",
    "preprocessor = ReviewPreprocessor(cachePath = topicPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31e7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text = \"text\"\n",
    "label_rating = \"rating\"\n",
    "reviewsToProcess: int = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d089806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 1000 reviews.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a random sample of reviews from the file.\n",
    "original_reviews, original_indices = preprocessor.LoadReviews(\n",
    "    file_path, reviewsToProcess, label_text, label_rating, seed\n",
    ")\n",
    "print(f\"\\nLoaded {len(original_reviews)} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec5b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing reviews...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Preprocessing reviews...\")\n",
    "# Build a dict mapping review text to its rating (this is useful for caching).\n",
    "reviews_dict: dict[str, float] = {\n",
    "    str(review[label_text]): review[label_rating] for review in original_reviews\n",
    "}\n",
    "# Call the class method on the preprocessor instance.\n",
    "preprocessed_reviews = preprocessor.PreprocessReviews(reviews_dict)\n",
    "del original_reviews,original_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fe8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the analyze_sentiment function\n",
    "def analyze_sentiment(pairs: tuple[str, str],sid = None) -> dict[str, dict]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment for a list of noun/adjective pairs using VADER.\n",
    "    Args:\n",
    "        pairs (list of tuples): List of tuples containing noun/adjective pairs.\n",
    "        sid (SentimentIntensityAnalyzer): Optional VADER sentiment analyzer instance.\n",
    "        If not provided, a new instance will be created.\n",
    "    Returns:\n",
    "        dict: A dictionary with sentiment scores for each pair, using VADER\n",
    "        format (compound, pos, neg, neu).\n",
    "    \"\"\"\n",
    "    if sid is None:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "    scores: dict[str, dict] = {}\n",
    "\n",
    "    for noun, adj in pairs:\n",
    "        phrase = f\"{adj} {noun}\"\n",
    "        score = sid.polarity_scores(phrase)\n",
    "        scores[phrase] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c05ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract adjective-noun pairs\n",
    "pairs: list[tuple[str, str]] = []\n",
    "nouns: list[str] = []\n",
    "# The dictionary associates the original review with its corrected form and\n",
    "# the adjective-noun pairs.\n",
    "reviews_dict: dict[tuple[str,str, str]] = {}\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for rawReview, rawReviewData in preprocessed_reviews.items():\n",
    "\n",
    "    # Check if the data we are about to calculate are already in the cache.\n",
    "    # If so, skip the calculation and use the cached data.\n",
    "    cachedReview = preprocessor.GetReviewFromCache(rawReview)\n",
    "    if cachedReview is not None and \"pairs\" in cachedReview:\n",
    "        # Use the cached data\n",
    "        pairs = cachedReview[\"pairs\"]\n",
    "        nouns = cachedReview[\"nouns\"]\n",
    "    else:\n",
    "        # If not, process the review to extract adjective-noun pairs.\n",
    "        # split sentences on hard punctuation (periods, exclamation marks, question marks)\n",
    "        sentences = re.split(r'(?<=[.!?]) +', rawReviewData[\"corrected\"])\n",
    "        pairs = []\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if len(sentence) < 4:\n",
    "                continue\n",
    "            # Process the sentence with SpaCy.\n",
    "            # This is the core idea of the method: we assume that the sentiment in a review\n",
    "            # is mainly expressed by nouns combined with adjectives, like in \"good music\"\n",
    "            # or \"awful service\"\n",
    "            # The extraction uses Spacy.\n",
    "            # - \"amod\" means adjectival modifier (e.g., \"good\" in \"good music\")\n",
    "            # - \"acomp\" means adjectival complement (e.g., \"good\" in \"the product is good\")\n",
    "            # - \"nsubj\" means nominal subject (e.g., \"product\" in \"the product is good\") \n",
    "            doc = nlp(sentence)\n",
    "            for token in doc:\n",
    "                if token.pos_ == \"NOUN\":\n",
    "                    # Token \"children\" are the words that depend on it.\n",
    "                    for child in token.children:\n",
    "                        if child.dep_ == \"amod\":\n",
    "                            # adjective modifier (e.g., \"good\" in \"good music\")\n",
    "                            pairs.append((token.text, child.text))\n",
    "                            nouns.append(token.text)\n",
    "                elif token.dep_ == \"acomp\":\n",
    "                    # adjectival complement (e.g., \"good\" in \"the product is good\").\n",
    "                    # Now search its subject (the noun).\n",
    "                    subjects = [child for child in token.head.children if child.dep_ == \"nsubj\"]\n",
    "                    if subjects:\n",
    "                        # Found, we can add the pair\n",
    "                        pairs.append((subjects[0].text, token.text))\n",
    "                        nouns.append(subjects[0].text)\n",
    "\n",
    "        # Lemmatization is useful for cases where singual and plural forms are used\n",
    "        # interchangeably, like \"good music\" and \"good musics\".\n",
    "        pairs = [(preprocessor.LemmatizeText(noun), adj) for noun, adj in pairs]\n",
    "        # Remove duplicates from pairs\n",
    "        pairs = sorted(list(set(pairs)))\n",
    "        # Recalculate the nouns based on the pairs\n",
    "        nouns = sorted(list(set([noun for noun, _ in pairs])))\n",
    "\n",
    "        # Add the pairs to the preprocessing cache.\n",
    "        # Note the use of item as the key, which is the original review text.\n",
    "#        preprocessor.AddSubitemsToReviewCache(rawReview, {\"pairs\": pairs})\n",
    "#        preprocessor.AddSubitemsToReviewCache(rawReview, {\"nouns\": nouns})\n",
    "\n",
    "    # Add the pairs to the review_dict for later sentiment analysis.\n",
    "    # Differently, the review_dict uses the corrected review text as the key.\n",
    "    reviews_dict[rawReview] = {\n",
    "        \"O-Score\": rawReviewData[\"score\"],\n",
    "        \"readable\": rawReviewData[\"readable\"],\n",
    "        \"corrected\": rawReviewData[\"corrected\"],\n",
    "        \"nouns\": nouns,\n",
    "        \"pairs\": pairs\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "if 0:\n",
    "    for rawReviewData in reviews_dict.values():\n",
    "        print(f\"Review: {rawReviewData['corrected'][:64]}\")\n",
    "        print(f\"\\tNouns: {rawReviewData['nouns']}\")\n",
    "        print(f\"\\tPairs: {rawReviewData['pairs']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating sentiment scores for the reviews...\n",
      "1 of 985 have relevant sentiments.\n",
      "2 of 985 have relevant sentiments.\n",
      "3 of 985 have relevant sentiments.\n",
      "4 of 985 have relevant sentiments.\n",
      "5 of 985 have relevant sentiments.\n",
      "6 of 985 have relevant sentiments.\n",
      "7 of 985 have relevant sentiments.\n",
      "8 of 985 have relevant sentiments.\n",
      "9 of 985 have relevant sentiments.\n",
      "10 of 985 have relevant sentiments.\n",
      "11 of 985 have relevant sentiments.\n",
      "12 of 985 have relevant sentiments.\n",
      "13 of 985 have relevant sentiments.\n",
      "14 of 985 have relevant sentiments.\n",
      "15 of 985 have relevant sentiments.\n",
      "16 of 985 have relevant sentiments.\n",
      "17 of 985 have relevant sentiments.\n",
      "18 of 985 have relevant sentiments.\n",
      "19 of 985 have relevant sentiments.\n",
      "20 of 985 have relevant sentiments.\n",
      "21 of 985 have relevant sentiments.\n",
      "22 of 985 have relevant sentiments.\n",
      "23 of 985 have relevant sentiments.\n",
      "24 of 985 have relevant sentiments.\n",
      "25 of 985 have relevant sentiments.\n",
      "26 of 985 have relevant sentiments.\n",
      "27 of 985 have relevant sentiments.\n",
      "28 of 985 have relevant sentiments.\n",
      "29 of 985 have relevant sentiments.\n",
      "30 of 985 have relevant sentiments.\n",
      "31 of 985 have relevant sentiments.\n",
      "32 of 985 have relevant sentiments.\n",
      "33 of 985 have relevant sentiments.\n",
      "34 of 985 have relevant sentiments.\n",
      "35 of 985 have relevant sentiments.\n",
      "36 of 985 have relevant sentiments.\n",
      "37 of 985 have relevant sentiments.\n",
      "38 of 985 have relevant sentiments.\n",
      "39 of 985 have relevant sentiments.\n",
      "40 of 985 have relevant sentiments.\n",
      "41 of 985 have relevant sentiments.\n",
      "42 of 985 have relevant sentiments.\n",
      "43 of 985 have relevant sentiments.\n",
      "44 of 985 have relevant sentiments.\n",
      "45 of 985 have relevant sentiments.\n",
      "46 of 985 have relevant sentiments.\n",
      "47 of 985 have relevant sentiments.\n",
      "48 of 985 have relevant sentiments.\n",
      "49 of 985 have relevant sentiments.\n",
      "50 of 985 have relevant sentiments.\n",
      "51 of 985 have relevant sentiments.\n",
      "52 of 985 have relevant sentiments.\n",
      "53 of 985 have relevant sentiments.\n",
      "54 of 985 have relevant sentiments.\n",
      "55 of 985 have relevant sentiments.\n",
      "56 of 985 have relevant sentiments.\n",
      "57 of 985 have relevant sentiments.\n",
      "58 of 985 have relevant sentiments.\n",
      "59 of 985 have relevant sentiments.\n",
      "\n",
      "100 of 985\n",
      "60 of 985 have relevant sentiments.\n",
      "61 of 985 have relevant sentiments.\n",
      "62 of 985 have relevant sentiments.\n",
      "63 of 985 have relevant sentiments.\n",
      "64 of 985 have relevant sentiments.\n",
      "65 of 985 have relevant sentiments.\n",
      "66 of 985 have relevant sentiments.\n",
      "67 of 985 have relevant sentiments.\n",
      "68 of 985 have relevant sentiments.\n",
      "69 of 985 have relevant sentiments.\n",
      "70 of 985 have relevant sentiments.\n",
      "71 of 985 have relevant sentiments.\n",
      "72 of 985 have relevant sentiments.\n",
      "73 of 985 have relevant sentiments.\n",
      "74 of 985 have relevant sentiments.\n",
      "75 of 985 have relevant sentiments.\n",
      "76 of 985 have relevant sentiments.\n",
      "77 of 985 have relevant sentiments.\n",
      "78 of 985 have relevant sentiments.\n",
      "79 of 985 have relevant sentiments.\n",
      "80 of 985 have relevant sentiments.\n",
      "81 of 985 have relevant sentiments.\n",
      "82 of 985 have relevant sentiments.\n",
      "83 of 985 have relevant sentiments.\n",
      "84 of 985 have relevant sentiments.\n",
      "85 of 985 have relevant sentiments.\n",
      "86 of 985 have relevant sentiments.\n",
      "87 of 985 have relevant sentiments.\n",
      "88 of 985 have relevant sentiments.\n",
      "89 of 985 have relevant sentiments.\n",
      "90 of 985 have relevant sentiments.\n",
      "91 of 985 have relevant sentiments.\n",
      "92 of 985 have relevant sentiments.\n",
      "93 of 985 have relevant sentiments.\n",
      "94 of 985 have relevant sentiments.\n",
      "95 of 985 have relevant sentiments.\n",
      "96 of 985 have relevant sentiments.\n",
      "97 of 985 have relevant sentiments.\n",
      "98 of 985 have relevant sentiments.\n",
      "99 of 985 have relevant sentiments.\n",
      "100 of 985 have relevant sentiments.\n",
      "101 of 985 have relevant sentiments.\n",
      "102 of 985 have relevant sentiments.\n",
      "103 of 985 have relevant sentiments.\n",
      "104 of 985 have relevant sentiments.\n",
      "105 of 985 have relevant sentiments.\n",
      "106 of 985 have relevant sentiments.\n",
      "107 of 985 have relevant sentiments.\n",
      "108 of 985 have relevant sentiments.\n",
      "109 of 985 have relevant sentiments.\n",
      "110 of 985 have relevant sentiments.\n",
      "111 of 985 have relevant sentiments.\n",
      "112 of 985 have relevant sentiments.\n",
      "113 of 985 have relevant sentiments.\n",
      "114 of 985 have relevant sentiments.\n",
      "115 of 985 have relevant sentiments.\n",
      "116 of 985 have relevant sentiments.\n",
      "117 of 985 have relevant sentiments.\n",
      "118 of 985 have relevant sentiments.\n",
      "119 of 985 have relevant sentiments.\n",
      "120 of 985 have relevant sentiments.\n",
      "121 of 985 have relevant sentiments.\n",
      "122 of 985 have relevant sentiments.\n",
      "123 of 985 have relevant sentiments.\n",
      "124 of 985 have relevant sentiments.\n",
      "125 of 985 have relevant sentiments.\n",
      "126 of 985 have relevant sentiments.\n",
      "127 of 985 have relevant sentiments.\n",
      "128 of 985 have relevant sentiments.\n",
      "129 of 985 have relevant sentiments.\n",
      "130 of 985 have relevant sentiments.\n",
      "131 of 985 have relevant sentiments.\n",
      "132 of 985 have relevant sentiments.\n",
      "133 of 985 have relevant sentiments.\n",
      "134 of 985 have relevant sentiments.\n",
      "135 of 985 have relevant sentiments.\n",
      "136 of 985 have relevant sentiments.\n",
      "\n",
      "200 of 985\n",
      "137 of 985 have relevant sentiments.\n",
      "138 of 985 have relevant sentiments.\n",
      "139 of 985 have relevant sentiments.\n",
      "140 of 985 have relevant sentiments.\n",
      "141 of 985 have relevant sentiments.\n",
      "142 of 985 have relevant sentiments.\n",
      "143 of 985 have relevant sentiments.\n",
      "144 of 985 have relevant sentiments.\n",
      "145 of 985 have relevant sentiments.\n",
      "146 of 985 have relevant sentiments.\n",
      "147 of 985 have relevant sentiments.\n",
      "148 of 985 have relevant sentiments.\n",
      "149 of 985 have relevant sentiments.\n",
      "150 of 985 have relevant sentiments.\n",
      "151 of 985 have relevant sentiments.\n",
      "152 of 985 have relevant sentiments.\n",
      "153 of 985 have relevant sentiments.\n",
      "154 of 985 have relevant sentiments.\n",
      "155 of 985 have relevant sentiments.\n",
      "156 of 985 have relevant sentiments.\n",
      "157 of 985 have relevant sentiments.\n",
      "158 of 985 have relevant sentiments.\n",
      "159 of 985 have relevant sentiments.\n",
      "160 of 985 have relevant sentiments.\n",
      "161 of 985 have relevant sentiments.\n",
      "162 of 985 have relevant sentiments.\n",
      "163 of 985 have relevant sentiments.\n",
      "164 of 985 have relevant sentiments.\n",
      "165 of 985 have relevant sentiments.\n",
      "166 of 985 have relevant sentiments.\n",
      "167 of 985 have relevant sentiments.\n",
      "168 of 985 have relevant sentiments.\n",
      "169 of 985 have relevant sentiments.\n",
      "170 of 985 have relevant sentiments.\n",
      "171 of 985 have relevant sentiments.\n",
      "172 of 985 have relevant sentiments.\n",
      "173 of 985 have relevant sentiments.\n",
      "174 of 985 have relevant sentiments.\n",
      "175 of 985 have relevant sentiments.\n",
      "176 of 985 have relevant sentiments.\n",
      "177 of 985 have relevant sentiments.\n",
      "178 of 985 have relevant sentiments.\n",
      "179 of 985 have relevant sentiments.\n",
      "180 of 985 have relevant sentiments.\n",
      "181 of 985 have relevant sentiments.\n",
      "182 of 985 have relevant sentiments.\n",
      "183 of 985 have relevant sentiments.\n",
      "184 of 985 have relevant sentiments.\n",
      "185 of 985 have relevant sentiments.\n",
      "186 of 985 have relevant sentiments.\n",
      "187 of 985 have relevant sentiments.\n",
      "188 of 985 have relevant sentiments.\n",
      "189 of 985 have relevant sentiments.\n",
      "190 of 985 have relevant sentiments.\n",
      "191 of 985 have relevant sentiments.\n",
      "192 of 985 have relevant sentiments.\n",
      "193 of 985 have relevant sentiments.\n",
      "194 of 985 have relevant sentiments.\n",
      "195 of 985 have relevant sentiments.\n",
      "196 of 985 have relevant sentiments.\n",
      "197 of 985 have relevant sentiments.\n",
      "198 of 985 have relevant sentiments.\n",
      "199 of 985 have relevant sentiments.\n",
      "200 of 985 have relevant sentiments.\n",
      "201 of 985 have relevant sentiments.\n",
      "202 of 985 have relevant sentiments.\n",
      "203 of 985 have relevant sentiments.\n",
      "204 of 985 have relevant sentiments.\n",
      "205 of 985 have relevant sentiments.\n",
      "206 of 985 have relevant sentiments.\n",
      "207 of 985 have relevant sentiments.\n",
      "208 of 985 have relevant sentiments.\n",
      "209 of 985 have relevant sentiments.\n",
      "210 of 985 have relevant sentiments.\n",
      "211 of 985 have relevant sentiments.\n",
      "212 of 985 have relevant sentiments.\n",
      "\n",
      "300 of 985\n",
      "213 of 985 have relevant sentiments.\n",
      "214 of 985 have relevant sentiments.\n",
      "215 of 985 have relevant sentiments.\n",
      "216 of 985 have relevant sentiments.\n",
      "217 of 985 have relevant sentiments.\n",
      "218 of 985 have relevant sentiments.\n",
      "219 of 985 have relevant sentiments.\n",
      "220 of 985 have relevant sentiments.\n",
      "221 of 985 have relevant sentiments.\n",
      "222 of 985 have relevant sentiments.\n",
      "223 of 985 have relevant sentiments.\n",
      "224 of 985 have relevant sentiments.\n",
      "225 of 985 have relevant sentiments.\n",
      "226 of 985 have relevant sentiments.\n",
      "227 of 985 have relevant sentiments.\n",
      "228 of 985 have relevant sentiments.\n",
      "229 of 985 have relevant sentiments.\n",
      "230 of 985 have relevant sentiments.\n",
      "231 of 985 have relevant sentiments.\n",
      "232 of 985 have relevant sentiments.\n",
      "233 of 985 have relevant sentiments.\n",
      "234 of 985 have relevant sentiments.\n",
      "235 of 985 have relevant sentiments.\n",
      "236 of 985 have relevant sentiments.\n",
      "237 of 985 have relevant sentiments.\n",
      "238 of 985 have relevant sentiments.\n",
      "239 of 985 have relevant sentiments.\n",
      "240 of 985 have relevant sentiments.\n",
      "241 of 985 have relevant sentiments.\n",
      "242 of 985 have relevant sentiments.\n",
      "243 of 985 have relevant sentiments.\n",
      "244 of 985 have relevant sentiments.\n",
      "245 of 985 have relevant sentiments.\n",
      "246 of 985 have relevant sentiments.\n",
      "247 of 985 have relevant sentiments.\n",
      "248 of 985 have relevant sentiments.\n",
      "249 of 985 have relevant sentiments.\n",
      "250 of 985 have relevant sentiments.\n",
      "251 of 985 have relevant sentiments.\n",
      "252 of 985 have relevant sentiments.\n",
      "253 of 985 have relevant sentiments.\n",
      "254 of 985 have relevant sentiments.\n",
      "255 of 985 have relevant sentiments.\n",
      "256 of 985 have relevant sentiments.\n",
      "257 of 985 have relevant sentiments.\n",
      "258 of 985 have relevant sentiments.\n",
      "259 of 985 have relevant sentiments.\n",
      "260 of 985 have relevant sentiments.\n",
      "261 of 985 have relevant sentiments.\n",
      "262 of 985 have relevant sentiments.\n",
      "263 of 985 have relevant sentiments.\n",
      "264 of 985 have relevant sentiments.\n",
      "265 of 985 have relevant sentiments.\n",
      "266 of 985 have relevant sentiments.\n",
      "267 of 985 have relevant sentiments.\n",
      "268 of 985 have relevant sentiments.\n",
      "269 of 985 have relevant sentiments.\n",
      "270 of 985 have relevant sentiments.\n",
      "271 of 985 have relevant sentiments.\n",
      "272 of 985 have relevant sentiments.\n",
      "273 of 985 have relevant sentiments.\n",
      "274 of 985 have relevant sentiments.\n",
      "275 of 985 have relevant sentiments.\n",
      "276 of 985 have relevant sentiments.\n",
      "277 of 985 have relevant sentiments.\n",
      "278 of 985 have relevant sentiments.\n",
      "279 of 985 have relevant sentiments.\n",
      "280 of 985 have relevant sentiments.\n",
      "281 of 985 have relevant sentiments.\n",
      "\n",
      "400 of 985\n",
      "282 of 985 have relevant sentiments.\n",
      "283 of 985 have relevant sentiments.\n",
      "284 of 985 have relevant sentiments.\n",
      "285 of 985 have relevant sentiments.\n",
      "286 of 985 have relevant sentiments.\n",
      "287 of 985 have relevant sentiments.\n",
      "288 of 985 have relevant sentiments.\n",
      "289 of 985 have relevant sentiments.\n",
      "290 of 985 have relevant sentiments.\n",
      "291 of 985 have relevant sentiments.\n",
      "292 of 985 have relevant sentiments.\n",
      "293 of 985 have relevant sentiments.\n",
      "294 of 985 have relevant sentiments.\n",
      "295 of 985 have relevant sentiments.\n",
      "296 of 985 have relevant sentiments.\n",
      "297 of 985 have relevant sentiments.\n",
      "298 of 985 have relevant sentiments.\n",
      "299 of 985 have relevant sentiments.\n",
      "300 of 985 have relevant sentiments.\n",
      "301 of 985 have relevant sentiments.\n",
      "302 of 985 have relevant sentiments.\n",
      "303 of 985 have relevant sentiments.\n",
      "304 of 985 have relevant sentiments.\n",
      "305 of 985 have relevant sentiments.\n",
      "306 of 985 have relevant sentiments.\n",
      "307 of 985 have relevant sentiments.\n",
      "308 of 985 have relevant sentiments.\n",
      "309 of 985 have relevant sentiments.\n",
      "310 of 985 have relevant sentiments.\n",
      "311 of 985 have relevant sentiments.\n",
      "312 of 985 have relevant sentiments.\n",
      "313 of 985 have relevant sentiments.\n",
      "314 of 985 have relevant sentiments.\n",
      "315 of 985 have relevant sentiments.\n",
      "316 of 985 have relevant sentiments.\n",
      "317 of 985 have relevant sentiments.\n",
      "318 of 985 have relevant sentiments.\n",
      "319 of 985 have relevant sentiments.\n",
      "320 of 985 have relevant sentiments.\n",
      "321 of 985 have relevant sentiments.\n",
      "322 of 985 have relevant sentiments.\n",
      "323 of 985 have relevant sentiments.\n",
      "324 of 985 have relevant sentiments.\n",
      "325 of 985 have relevant sentiments.\n",
      "326 of 985 have relevant sentiments.\n",
      "327 of 985 have relevant sentiments.\n",
      "328 of 985 have relevant sentiments.\n",
      "329 of 985 have relevant sentiments.\n",
      "330 of 985 have relevant sentiments.\n",
      "331 of 985 have relevant sentiments.\n",
      "332 of 985 have relevant sentiments.\n",
      "333 of 985 have relevant sentiments.\n",
      "334 of 985 have relevant sentiments.\n",
      "335 of 985 have relevant sentiments.\n",
      "336 of 985 have relevant sentiments.\n",
      "337 of 985 have relevant sentiments.\n",
      "338 of 985 have relevant sentiments.\n",
      "339 of 985 have relevant sentiments.\n",
      "340 of 985 have relevant sentiments.\n",
      "341 of 985 have relevant sentiments.\n",
      "342 of 985 have relevant sentiments.\n",
      "343 of 985 have relevant sentiments.\n",
      "344 of 985 have relevant sentiments.\n",
      "345 of 985 have relevant sentiments.\n",
      "346 of 985 have relevant sentiments.\n",
      "347 of 985 have relevant sentiments.\n",
      "\n",
      "500 of 985\n",
      "348 of 985 have relevant sentiments.\n",
      "349 of 985 have relevant sentiments.\n",
      "350 of 985 have relevant sentiments.\n",
      "351 of 985 have relevant sentiments.\n",
      "352 of 985 have relevant sentiments.\n",
      "353 of 985 have relevant sentiments.\n",
      "354 of 985 have relevant sentiments.\n",
      "355 of 985 have relevant sentiments.\n",
      "356 of 985 have relevant sentiments.\n",
      "357 of 985 have relevant sentiments.\n",
      "358 of 985 have relevant sentiments.\n",
      "359 of 985 have relevant sentiments.\n",
      "360 of 985 have relevant sentiments.\n",
      "361 of 985 have relevant sentiments.\n",
      "362 of 985 have relevant sentiments.\n",
      "363 of 985 have relevant sentiments.\n",
      "364 of 985 have relevant sentiments.\n",
      "365 of 985 have relevant sentiments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_reviews_dict: dict[str, list[dict]] = {}\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "index: int = 0\n",
    "\n",
    "print(\"\\nCalculating sentiment scores for the reviews...\")\n",
    "for rawReview, rawReviewData in reviews_dict.items():\n",
    "\n",
    "    index += 1\n",
    "    if (index % 100) == 0:\n",
    "        print(f\"\\n{index} of {len(reviews_dict)}\")\n",
    "\n",
    "    pairs = rawReviewData[\"pairs\"]\n",
    "    # Calculate the sentiment scores for the pairs, then filter out\n",
    "    # those with a compound score below 0.05\n",
    "    scores = analyze_sentiment(pairs = pairs, sid = sid)\n",
    "    filtered_pairs = [\n",
    "        (pair.split()[1], pair.split()[0]) \n",
    "        for pair, score in scores.items()\n",
    "        if abs(score['compound']) >= 0.05\n",
    "    ]\n",
    "    V_Pairs: float = np.sum([score['compound'] for score in scores.values()])\n",
    "    # Skip if no pair meets the criteria\n",
    "    if not filtered_pairs:\n",
    "        continue\n",
    "     # Calculate and store:\n",
    "    # - V-whole: the compound score of the review (VADER on the whole review)\n",
    "    # - O-Score: the original score of the review (from the dataset)\n",
    "    V_Whole = sid.polarity_scores(rawReview)[\"compound\"]\n",
    "    O_Score = rawReviewData[\"O-Score\"]\n",
    "\n",
    "    # Add a new key to the filtered_reviews_dict dictionary. We also store\n",
    "    # compound, it will be used later.\n",
    "    filtered_reviews_dict[rawReview] = {\n",
    "        \"readable\": rawReviewData[\"readable\"],\n",
    "        \"corrected\": rawReviewData[\"corrected\"],\n",
    "        \"pairs\": filtered_pairs,\n",
    "        \"nouns\": sorted(list(set([noun for noun, _ in filtered_pairs]))),\n",
    "        \"V-pairs\": V_Pairs,\n",
    "        \"O-Score\": O_Score,\n",
    "        \"V-whole\": V_Whole\n",
    "    }\n",
    "\n",
    "    # Also update the cache, as the pairs and nouns may have changed.\n",
    "    # We are not interested in storing the scores.\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"pairs\": filtered_pairs})\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"nouns\": filtered_reviews_dict[rawReview][\"nouns\"]})\n",
    "\n",
    "print(f\"{len(filtered_reviews_dict)} of {len(reviews_dict)} have relevant sentiments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d7623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC"
     ]
    }
   ],
   "source": [
    "# In this last step, we invoke a LLM to parse the sentiment score, the so-called \"L-score\".\n",
    "# The LLM will be asked to parse the review text and the noun list, and return a score.\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "parsed_scores: dict[str, dict] = {}\n",
    "index: int = 0\n",
    "\n",
    "print(\"\\nCalculating LLM scores for the reviews...\")\n",
    "# Iterate through each review in the filtered_reviews_dict\n",
    "for rawReview, rawReviewData in filtered_reviews_dict.items():\n",
    "    index += 1\n",
    "    if (index % 100) == 0:\n",
    "        print(f\"\\n{index} of {len(filtered_reviews_dict)}\")\n",
    "    # Invoke parseScore() and store the result in the dictionary\n",
    "    parsed_scores[rawReview] = sentimentsManager.parseScore(rawReviewData[\"readable\"], rawReviewData[\"nouns\"])\n",
    "    # Calculate the LLM score as the sum of the parsed scores, then\n",
    "    # add it to the review dictionary.\n",
    "    plusValues = sum([score for score in parsed_scores[rawReview].values() if score > 0])\n",
    "    minusValues = sum([score for score in parsed_scores[rawReview].values() if score < 0])\n",
    "    neutralValues = sum([score for score in parsed_scores[rawReview].values() if score == 0])\n",
    "    llm_score = sum(parsed_scores[rawReview].values())\n",
    "    # Update the review dictionary with the LLM score\n",
    "    rawReviewData[\"L-score\"] = llm_score\n",
    "    rawReviewData[\"L-scoreP\"] = plusValues\n",
    "    rawReviewData[\"L-scoreM\"] = minusValues\n",
    "    rawReviewData[\"L-scoreN\"] = neutralValues\n",
    "    # Add the LLM score to the cache\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"L-score\": llm_score})\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"L-scoreP\": plusValues})\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"L-scoreM\": minusValues})\n",
    "    preprocessor.AddSubitemsToReviewCache(rawReview, {\"L-scoreN\": neutralValues})\n",
    "print(\"\\nDone.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6741e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the filtered results from the new dictionary\n",
    "if 0:\n",
    "    for rawReview, rawReviewData in filtered_reviews_dict.items():\n",
    "        print(f\"Review: {rawReview[:32]}...\")\n",
    "        print(f\"\\tNouns: {rawReviewData['nouns']}\")\n",
    "        print(f\"\\tPairs: {rawReviewData['pairs']}\")\n",
    "        print(f\"\\tO-Score (stars): {rawReviewData['O-Score']:.2f}\")\n",
    "        print(f\"\\tL-Score: {rawReviewData['L-score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write the results to a CSV file with adjusted rewiews and all the scores.\n",
    "import csv\n",
    "import time\n",
    "result_file = os.path.join(topicSeedPath, f\"scores.csv\")\n",
    "with open(result_file, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "\n",
    "    fieldnames = [\n",
    "        'timestamp','O-score',\n",
    "        'L-score','L-scoreP','L-scoreM','L-scoreN',\n",
    "        'V-Whole','readable','corrected','review'\n",
    "    ]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for rawReview, rawReviewData in filtered_reviews_dict.items():\n",
    "        writer.writerow({\n",
    "            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'O-score': preprocessed_reviews[rawReview][\"score\"],\n",
    "            'L-score': f\"{rawReviewData['L-score']:.2f}\",\n",
    "            'L-scoreP': f\"{rawReviewData['L-scoreP']:.2f}\",\n",
    "            'L-scoreM': f\"{rawReviewData['L-scoreM']:.2f}\",\n",
    "            'L-scoreN': f\"{rawReviewData['L-scoreN']:.2f}\",\n",
    "            'V-Whole': f\"{rawReviewData['V-whole']:.2f}\",\n",
    "            'readable': f\"{rawReviewData['readable']}\",\n",
    "            'corrected': rawReviewData[\"corrected\"],\n",
    "            'review': rawReview\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now select reviews and save them to a file for human scoring.\n",
    "import random\n",
    "result_file = os.path.join(topicSeedPath, f\"scores.csv\")\n",
    "# Select up to 100 reviews\n",
    "num_reviews_to_select = min(100, len(filtered_reviews_dict))\n",
    "random.seed(seed)  # Set the seed for reproducibility\n",
    "selected_reviews = random.sample(list(filtered_reviews_dict.items()), num_reviews_to_select)\n",
    "# Save the selected reviews to a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b72df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "selected_reviews_file = os.path.join(topicSeedPath, f\"selected_reviews.csv\")\n",
    "# Check if the file already exists and ask the user if they want to overwrite it\n",
    "if os.path.exists(selected_reviews_file):\n",
    "    overwrite = input(f\"{selected_reviews_file} already exists. Overwrite it? (y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"Exiting without overwriting the file.\")\n",
    "        exit()\n",
    "\n",
    "with open(selected_reviews_file, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['readable','hscore','review']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for rawReview, rawReviewData in selected_reviews:\n",
    "        writer.writerow({\n",
    "            'readable': f\"{rawReviewData['readable']}\",\n",
    "            'hscore': 0,\n",
    "            'review': rawReview\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code stops here. Please manually grade the reviews and run the next script to plot the results.\n"
     ]
    }
   ],
   "source": [
    "print(\"The code stops here. Please manually grade the reviews and run the next script to plot the results.\")\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee9c712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine human scores and preprocessing cache for ML training\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Read the updated file with human scores\n",
    "with open(selected_reviews_file, mode='r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        review = row['review']\n",
    "        hscore = float(row['hscore'])  # Convert human score to float\n",
    "\n",
    "        # Retrieve data from the preprocessing cache\n",
    "        cached_data = preprocessor.GetReviewFromCache(review)\n",
    "        if cached_data:\n",
    "            O_score = cached_data.get(\"score\", 0)\n",
    "            L_scoreP = cached_data.get(\"L-scoreP\", 0)\n",
    "            L_scoreM = cached_data.get(\"L-scoreM\", 0)\n",
    "            L_scoreN = cached_data.get(\"L-scoreN\", 0)\n",
    "\n",
    "            # Append features to X and target to Y\n",
    "            X.append([O_score, L_scoreP, L_scoreM, L_scoreN])\n",
    "            Y.append(hscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e95a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.40\n",
      "R^2 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and testing sets (85% train, 15% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=seed)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model = RandomForestRegressor(random_state=seed)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e32a963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to data\\Magazine_Subscriptions\\1967\\ML_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = os.path.join(topicSeedPath, \"ML_model.pkl\")\n",
    "with open(model_file, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved to {model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375eb5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readable Review: i paid for a two year subscription, after two issues they changed to a 'web only' magazine and stopped sending me issues. so now i paid to subscribe to some blog, worthless!\n",
      "Predicted Human Score: 3.71\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Select another review from the filtered_reviews_dict\n",
    "\n",
    "random.seed()  # Ensure reproducibility\n",
    "random_review_key = random.choice(list(filtered_reviews_dict.keys()))\n",
    "random_review_data = filtered_reviews_dict[random_review_key]\n",
    "\n",
    "# Extract features for prediction\n",
    "features = [\n",
    "    random_review_data[\"O-Score\"],\n",
    "    random_review_data[\"L-scoreP\"],\n",
    "    random_review_data[\"L-scoreM\"],\n",
    "    random_review_data[\"L-scoreN\"]\n",
    "]\n",
    "\n",
    "# Predict the human score\n",
    "predicted_hscore = model.predict([features])[0]\n",
    "\n",
    "# Print the readable review and the predicted score\n",
    "print(f\"Readable Review: {random_review_data['readable']}\")\n",
    "print(f\"Predicted Human Score: {predicted_hscore:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades: dict[str, int] = {}\n",
    "\n",
    "if 0:\n",
    "    f = open(os.path.join(topicSeedPath, \"grades.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    for rawReview, rawReviewData in filtered_reviews_dict.items():\n",
    "        grades[rawReview] = sentimentsManager.assignGradeToReview(rawReviewData[\"readable\"])\n",
    "        f.write(f\"{grades[rawReview]}, \\\"{rawReviewData[\"readable\"]}\\\"\\n\")\n",
    "        f.flush()\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
