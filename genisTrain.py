#
# GENIS - Grading with Explainability and No Intrinsic Saturation
#
# genisTrain.py - Script to train a linear regression model for sentiment analysis
# using features extracted from reviews.
# Before running this script, you should execute genisCalc.py to get the data needed.
#
import csv
import os
import argparse
import datetime
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score, f1_score
from preprocessing import ReviewPreprocessor

ver: str = "0.9.0"
# Labels for the text and rating in the jsonl file
# The default values are the ones used in the Amazon reviews dataset
label_text: str = "text"
label_rating: str = "rating"

# Create an instance of class used in the script.
# Initialization postponed as it requires the cache path, calculated later.
preprocessor: ReviewPreprocessor = None

# Lists to store the data acquired from the csv files and the caches
Reviews: list[str] = []
X: list[list[float,float,float,float]] = []
Y: list[float] = []
V_scores: list[float] = []


helpMessage = """\
GENIS - Grading with Explainability and No Intrinsic Saturation

This script trains a linear regression model for sentiment analysis using features extracted from reviews.
To run, genisTrain requires a data file called selected_reviews.csv and the preprocessing cache generated by genisCalc.py.
Moreover, selected_reviews.csv must be modified beforehand to include the human scores for the reviews.

To locate these files, genisTrain uses two command line parameters:

- a positional parameter with the subdirectory of 'data/' where files to process are stored.
- the optional parameter -s or --seed is the random seed used with genisCalc.py (default 1967)

For example:

    python genisTrain.py music -s 42

This will look for the cache in data/music and the csv in data/music/42/selected_reviews.csv.
"""

print(f"GENIS trainer v{ver}")
parser = argparse.ArgumentParser(
    description=helpMessage,
    formatter_class=argparse.RawTextHelpFormatter
)
parser.add_argument(
    "paths",
    type=str,
    nargs="+",  # Accept one or more directories
    help="List of directories under 'data/' where processed files are stored"
)
parser.add_argument("-s", "--seed", type=int, help="Random seed (default 1967)", default=1967)
parser.add_argument("-v", "--version", action="version", version=f"{ver}")
args = parser.parse_args()

# Process command line arguments

for path in args.paths:

    cachePath = os.path.join("data", path)
    filePath = os.path.join(cachePath, f"{args.seed}", "selected_reviews.csv")
    if not os.path.exists(cachePath):
        print(f"Directory data/{path} not found.")
        exit(1)
    if not os.path.exists(filePath):
        print(f"File {filePath} not found.")
        exit(1)

    # Instantiate the ReviewPreprocessor class (which now handles cache initialization)
    preprocessor = ReviewPreprocessor(cachePath = cachePath)

    # Read the updated file with human scores
    counter: int = 0
    with open(filePath, mode='r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            review = row['review']
            hscore = float(row['hscore'])  # Convert human score to float

            # Retrieve data from the preprocessing cache
            cached_data = preprocessor.GetReviewFromCache(review)
            if cached_data:
                O_score = cached_data.get("score", 0)
                L_scoreP = cached_data.get("L-scoreP", 0)
                L_scoreM = cached_data.get("L-scoreM", 0)
                L_scoreN = cached_data.get("L-scoreN", 0)
                V_score = cached_data.get("V-Whole", 0)

                # Append features to X and target to Y
                X.append([O_score, L_scoreP, L_scoreM, L_scoreN])
                # Convert human score to string to force the regressor to
                # work to a classification problem instead of a regression one.
                Y.append(str(hscore))
                Reviews.append(cached_data.get("readable", ""))
                V_scores.append(V_score)
                counter += 1

    print(f"Loaded {counter} reviews from {filePath}")

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, Y_train, Y_test, Rev_train, Rev_test, V_train, V_test = train_test_split(X, Y, Reviews, V_scores, test_size=0.20, random_state=args.seed)

model = RandomForestClassifier(n_estimators=16, min_samples_split=5, random_state=args.seed)
print(f"Training model with {len(X_train)} samples")
model.fit(X_train, Y_train)
# Make predictions on the test set
print(f"Predicting {len(X_test)} samples")
Y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(Y_test, Y_pred)
r2 = r2_score(Y_test, Y_pred)
print(f"Model evaluation on training set:")
print(f"F1 Score: {f1_score(Y_train, model.predict(X_train), average='weighted'):.2f}")
print(f"Model evaluation on test set:")
print(f"F1 Score: {f1_score(Y_test, Y_pred, average='weighted'):.2f}")
# calculate micro and macro f1 scores
print(f"Micro F1 Score: {f1_score(Y_test, Y_pred, average='micro'):.2f}")
print(f"Macro F1 Score: {f1_score(Y_test, Y_pred, average='macro'):.2f}")



# Write the contents of all files into a new CSV file
with open('data/overall_results.csv', 'w', encoding='utf-8', newline='') as file:
    writer = csv.writer(file)

    for x, y, v, review in zip(X_train, Y_train, V_train, Rev_train):
        writer.writerow([
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # timestamp
            "tr",  # type (train/test)
            x[0],  # O-score
            x[1],  # L-scoreP
            x[2],  # L-scoreM
            x[3],  # L-scoreN
            float(y),  # Y (human score)
            float(y),  # Y-pred (same as Y for training data)
            v,  # VADER score
            review,  # review file
        ])
    for x, y, y_pred, v, review in zip(X_test, Y_test, Y_pred, V_test, Rev_test):
        writer.writerow([
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # timestamp
            "te",  # type (train/test)
            x[0],  # O-score
            x[1],  # L-scoreP
            x[2],  # L-scoreM
            x[3],  # L-scoreN
            float(y),  # Y (human score)
            float(y_pred),  # Y-pred (to be filled later)
            v,  # VADER score
            review,  # review file
        ])
file.close()
print("Results written to data/overall_results.csv")
print("Done.")
